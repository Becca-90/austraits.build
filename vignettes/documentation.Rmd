---
title: "Descriptor of the `Austraits` data compilation - a curated plant trait database for the Australian flora"
author: "Daniel Falster, Rachael Gallagher, Sam Andrew, Dony Indiarto, James Lawson, Lizzy Wenk"
date: "`r Sys.Date()`"
output:
  html_document:
    keep_md: yes
    smart: no
    theme: yeti
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: true
editor_options:
  chunk_output_type: console
---

<!-- hack to get indentation on 3rd level of floating TOC; see
https://stackoverflow.com/questions/46201753/rmarkdown-indentation-of-toc-items-in-html-output
 -->
<script>
$(document).ready(function() {
  $items = $('div#TOC li');
  $items.each(function(idx) {
    num_ul = $(this).parentsUntil('#TOC').length;
    $(this).css({'text-indent': num_ul * 10, 'padding-left': 0});
  });

});
</script>

```{r setup, echo=FALSE, message=FALSE, warning=FALSE, results="hide"}
# knitr defaults
root.dir = rprojroot::find_root("remake.yml")
knitr::opts_knit$set(root.dir = root.dir)
knitr::opts_chunk$set(echo=FALSE, cache=FALSE, results='asis', message=FALSE, warning=FALSE)

# default for table format
options(knitr.table.format = "html")

# Guidelines for writing report code
# - use tidyverse style and format: http://htmlpreview.github.io/?https://github.com/nicercode/2018_BEES_regression/blob/master/tidyverse.html
# - use kableExtra for styling: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html
# - use knitr chunck options: https://rmarkdown.rstudio.com/lesson-3.html

```

```{r, echo=FALSE, message=FALSE, warning=FALSE, results="hide"}
library(knitr)
library(dplyr)
library(kableExtra)

source("R/austraits.R")
source("R/steps.R")
source("R/pre_process.R")
source("R/support.R")
source("R/report_utils.R")

## Assumes to items exist in global name space
if(!exists("austraits")) {
  austraits <- remake::make("austraits")
  # stop("austraits must exist in global name space to knit a report")
}

definitions <- austraits$definitions

knitr::opts_chunk$set(fig.cap='', fig.path = file.path(root.dir,"vignettes/figures", paste0("documentation","_")))
```

# Overview

This document describes the AusTraits compilation - a database of plant traits for the Australian Flora. AusTraits synthesises data on `r austraits$data$trait_name %>% unique() %>% length()` traits from `r austraits$metadata %>% length()` different sources, including field campaigns, published literature, taxonomic monographs, and individual species descriptions. Traits vary in scope from physiological measures of performance (e.g. photosynthetic gas exchange, water-use efficiency) to morphological parameters (e.g. leaf size, seed size, maximum height) which link to ecological strategy variation. AusTraits contains curated and harmonised species- and genus-level observations coupled to, where available, contextual information on site properties. 

This document provides information on the structure of AusTraits and corresponds to Version `r austraits$definitions$austraits$elements$version$value` of the dataset. An overview of the actual data is provided in another document: see XXXX.

# Ethos and Usage

We envision AusTraits as an on-going collaborative community resource for easily archiving and sharing trait data to increase our collective understanding the Australian flora.

Prior to the development of AusTraits, data on Australian plant traits existed as a series of largely disconnected datasets collected by individual laboratories or initiatives. Our goal is to harmonise these different sources.

## License

## Access


## Citation

Force 11 data citation: https://www.force11.org/datacitationprinciples

Wilkinson et al 2015 The FAIR Guiding Principles for scientific data management and stewardship http://doi.org/10.1038/sdata.2016.18

## Transparency 

To facilitate the sharing of trait data under the FAIR principles (Free, , AusTraits uses a fully-reproducible workflow which exposes the decisions made in the processing of data into a harmonised and curated dataset (Figure 1). For instance, AusTraits makes no alterations to the primary datasets provided by co-authors on this Data Descriptor, instead making use of R packages such a make and remake to configure and harmonise (standardise) data into a single curated resource. Several additional quality-assurance steps are undertaken, including detailed error-checking by dataset custodians facilitated by the generation of bespoke reports of their data relative to all observation in AusTraits and the implementation of a series of tests in the remake pipeline (e.g. constraining trait values to plausible minima and maxima) (see Methods for full details). Whilst all care is taken to curate datasets in AusTraits this is not intended to absolve individual researchers from ensuring the appropriate use of the data provided. 

# Data structures

## General approach

The Extensible Observation Ontology (OBOE) is a formal ontology for capturing the semantics of scientific observation and measurement. The ontology supports researchers to add detailed semantic annotations to scientific data, thereby clarifying the inherent meaning of scientific observations. 

> Mark Schildhauer, Matthew B. Jones, Shawn Bowers, Joshua Madin, Sergeui Krivov, Deana Pennington, Ferdinando Villa, Benjamin Leinfelder, Christopher Jones, and Margaret O'Brien. 2016. OBOE: the Extensible Observation Ontology, version 1.1. KNB Data Repository. [doi:10.5063/F11C1TTM](http://doi.org/10.5063/F11C1TTM)

The original publication describing the OBOE concept is:

> Madin, J., S. Bowers, M. Schildhauer, S. Krivov, D. Pennington, and F. Villa. 2007. An ontology for describing and synthesizing ecological observation data. Ecological Informatics 2:279–296. [doi:10.1016/j.ecoinf.2007.05.004](http://doi.org/10.1016/j.ecoinf.2007.05.004)

Source code on Github: [NCEAS/oboe](https://github.com/NCEAS/oboe)

## Elements of Austraits

The AusTraits database is with the follow main components:

```{r, results="show", comment = ''}
names(austraits) %>% 
  create_tree_branch("austraits") %>%
  writeLines()
```

Each component is defined as follows


```{r}
print_defintions_element <- function(elements) {
  if(elements$type == "character") {
    sprintf("content: %s\n", elements$value) %>% 
      writeLines()
  }
  
  if(elements$type == "table") {
    
    sprintf("content: \n") %>% 
      writeLines()

    elements$elements %>% 
      list1_to_df() %>%
      my_kable_styling() %>% 
      writeLines()
  }
}

for(v in names(austraits)) {
  elements <- austraits$definitions$austraits$elements[[v]]
  
  sprintf("### %s\n\ndescription: %s\n", v, elements$description) %>% 
    writeLines()
  
  elements %>%
    print_defintions_element()

  writeLines(c(""))
}
```

# Trait definitions

Below is the standard defintion for each trait in AusTraits (drawn from the the file `config/definitions.yml`). Traits are labelled as either `numeric` or `categorical`. Numeric traits also include 

```{r traits}
for(trait in names(austraits$definitions$traits$elements)) {
  elements <- austraits$definitions$traits$elements[[trait]]
  
  data_trait <- austraits$data %>%
    filter(trait_name == trait)
  
  c(
    sprintf("**%s**\n\n", trait),
    sprintf("- label: %s", elements$label ),
    sprintf("- description: %s", elements$description ),
    sprintf("- number of records: %s", data_trait %>% nrow() ),
    sprintf("- number of studies: %s", data_trait %>% pull(dataset_id) %>% unique() %>% length() ),
    sprintf("- type: %s%s", elements$type,
      ifelse(elements$type == "numeric",  
         sprintf("\n- units: %s", elements$units), "")),
    ifelse(elements$type == "numeric",  
         sprintf("- allowable range: %s - %s %s", elements$values$minimum,
            elements$values$maximum, elements$units),
         sprintf("- allowable values:\n%s\n",  
                 paste0("    - *",elements$values %>% names(), "*: ", elements$values %>% unlist(), collapse="\n"))),
    ""
  ) %>%
    writeLines()
}
```

# Observation IDs

Each trait measurement has an associated `observation_id`. Observation IDS bind together related measurements within a dataset. For example, if multiple traits were collected on the same individual, the `observation_id` allows us to gather these together. For floras, which report a species averages, the `observation_id` is determined via the species name. Importantly, the `observation_id` allows translation between long  (e.g. with variables `trait_name` and `value`) and wide (e.g. with traits as columns) formats.

Generally, `observation_id` has the format `dataset_id_XX` where `XX` is a unique number within each dataset.

For datasets that arrive in wide format we assume each row has a unique `observation_id`. 

For datasets that arrive in long format, the `observation_id` is assigned based on a specified grouping variable. This variable can be specified in the `metadata.yml` file under the section `variable_match`. If missing, `observation_id` is assigned based on `species_name`. 

# Value types

Each trait measurement has an associated `value_type`, which gives ``r austraits$definitions$value_type$description``. Possible values are:

```{r value_type}
austraits$definitions$value_type$values %>% 
  list1_to_df()  %>% 
  my_kable_styling() %>% 
  writeLines()
```

# Species taxonomy

Within Austraits there are records for `r austraits$data$species_name %>% unique() %>% length()` different species. A full list of all known species is available in the table `species_list` (see details above).

We have attempted to align species names with known taxonomic units, focussing primarily on the [`The Plant List` (TPL)](http://www.theplantlist.org/) -- a global working list of all known plant species. In addition we have tried to align these names with the [`Australian Plant Census` (APC)](https://biodiversity.org.au/nsl/services/apc) and the [`Australian Plant Names Index` (APNI)](https://biodiversity.org.au/nsl/services/APNI). The `APNI_ID` can also be used to access relevant records for the species in the [`Atlas of Living Australia`](https://bie.ala.org.au/) (ALA).

Links to species records in these systems can be accessed via the relevant IDs as in these examples. 

- The Plant List: [http://www.theplantlist.org/tpl1.1/record/kew-450649](http://www.theplantlist.org/tpl1.1/record/kew-450649) where `kew-450649` is the `TPL_ID`
- Australian Plant Census: [https://biodiversity.org.au/nsl/services/node/apc/2908862](https://biodiversity.org.au/nsl/services/node/apc/2908862) where `2908862` is the `APC_ID`
- Australian Plant Names Index: [http://id.biodiversity.org.au/node/apni/2899106](http://id.biodiversity.org.au/node/apni/2899106
) where `2899106` is the `APNI_ID`
- Atlas of Living Australia: [https://bie.ala.org.au/species/http://id.biodiversity.org.au/node/apni/2899106](https://bie.ala.org.au/species/http://id.biodiversity.org.au/node/apni/2899106) where `2899106` is the `APNI_ID`.


# Building austraits

## Approach

## File structure



```
rdflib-review
├── README.md
├── index.Rmd
├── pkgreview.md
└── rdflib-review.Rproj
```

## Rebuilding from scratch

```{r, eval=FALSE}
data <- read_csv(filename_data_raw, col_types = cols()) %>%
    custom_manipulation(metadata[["config"]][["custom_R_code"]])() %>%
    parse_data(dataset_id, metadata) %>%
    add_all_columns(definitions, "data") %>%
    flag_unsupported_traits(definitions) %>%
    convert_units(definitions, unit_conversion_functions) %>%
    flag_unsupported_values(definitions) %>%
    update_taxonomy(metadata) %>%
    mutate(value=tolower(value))
```

# Format of data for each study

## Data.csv

## Metadata.yml  

Format for Contributed Studies

The metadata is compiled in a `.yml` file, a structured data file where information is presented in a hierarchical format (see Appendix for details).  There are 7 values at the top hierarchical level: `source`, `people`, `dataset`, `config`, `traits`, `substitutions`, and `taxonomic_updates` and these are described below.

### Source


In general we aim to reference the primary source. References are written in structured yml format, under the category `source` and then under titles `primary` and `secondary`. Here are some examples for different types of source:

A book:

```
source:
  primary:
    key: Cooper_2004
    bibtype: Book
    author: Wendy Cooper, William T. Cooper
    year: 2004
    title: Fruits of the Australian tropical rainforest
    publisher: Nokomis Editions
    isbn: '9780958174213'
  secondary: .na
```

A journal article:

```
source:
  primary:
    key: Falster_2005
    bibtype: Article
    author: Daniel S. Falster, Mark Westoby
    year: 2005
    title: Alternative height strategies among 45 dicot rain forest species from tropical
      Queensland, Australia
    journal: Journal of Ecology
    volume: 93
    pages: 521--535
    publisher: Wiley-Blackwell
    doi: 10.1111/j.0022-0477.2005.00992.x
    url: http://dx.doi.org/10.1111/j.0022-0477.2005.00992.x
  secondary: .na
```

An online resource:

```
source:
  primary:
    key: WAH_1998
    bibtype: Misc
    author: Western Australian Herbarium
    year: 1998
    title: FloraBase--the Western Australian Flora
    publisher: Department of Parks and Wildlife
    url: https://florabase.dpaw.wa.gov.au/
  secondary: .na
```

An unpublished resource:

```
source:
  primary:
    key: Duncan_1998
    bibtype: Unpublished
    author: David H. Duncan
    year: 1998
    title: Leaf anatomy of Australian plant species
    note: Collected while at Macquarie University
  secondary: .na
```

Note that in these first examples `secondary` is set as `.na`. If a secondary source is included it may look like:

```
  primary:
    key: Chave_2009
    bibtype: Article
    author: Jerome Chave, David Coomes, Steven Jansen, Simon L. Lewis, Nathan G. Swenson,
      Amy E. Zanne
    year: 2009
    title: Towards a worldwide wood economics spectrum
    journal: Ecology Letters
    volume: 12
    pages: 351--366
    publisher: Wiley-Blackwell
    doi: 10.1111/j.1461-0248.2009.01285.x
    url: http://dx.doi.org/10.1111/j.1461-0248.2009.01285.x
  secondary:
    key: Zanne_2009
    bibtype: Misc
    author: Amy E. Zanne, G. Lopez-Gonzalez, David A. Coomes, Jugo Ilic, Steven Jansen,
      Simon L. Lewis, Regis B. Miller, Nathan G. Swenson, Michael C. Wiemann, Jerome
      Chave
    year: 2009
    title: 'Data from: Towards a worldwide wood economics spectrum'
    volume: .na
    pages: .na
    publisher: Dryad Digital Repository
    doi: 10.5061/dryad.234
    url: https://doi.org/10.5061/dryad.234
 ```

General guidelines for describing a source

- elements are names as in [bibtex format](https://en.wikipedia.org/wiki/BibTeX)
- maximum of one primary and secondary source allowed
- a secondary source may be needed if the main collector is not an author on the paper where data was released, or data were otherwise released via a subsequent study.
- keys should be named in the format `Surname_year`.

### People

This includes a list of the different contributors to the study, their respective institutions and roles in the study.

### Dataset


### Config

The data under `config` indicates the basic format of the submitted data file. For instance:

### Traits

The level `traits` provides to distinct functions. The first is to map the contributed traits into the Austraits trait names and units. The second is to document information on the collection and meaning for the submitted trait values. In particular for each trait submitted to Austraits, there is the following information:

Units: These are converted to standardized units through the file “unit_conversions.csv” in the folder config. If no units are given an educated guess is made based on the values submitted.

Value type

- for expert opinion should indicate who

### Substitutions

The `metadata.yml` file for each study also contains a list of substitutionsthat are applied to specific variables in the dataset. These changes are documented in the following format:


```
substitutions:
- trait_name: life_history
  find: p
  replace: perennial
- trait_name: plant_growth_form
  find: s
  replace: shrub
- ...
```


### Taxonomic updates

The `metadata.yml` file for each study also contains a list of taxonomic name changes that are applied to the dataset. These changes are documented in the following format:

```
taxonomic_updates:
- find: Carissa lanceolata
  replace: Carissa spinarum
  reason: Synonym reported by TaxonStand (2018-09-19)
- find: Melaleuca pallida
  replace: Callistemon pallidus
  reason: Synonym reported by TaxonStand (2018-09-19)
- ...
```

We've implemented code to semi-automate the checking of names using the R package [Taxonstand](https://cran.r-project.org/web/packages/Taxonstand/index.html) (for more documentation see [here](https://www.rdocumentation.org/packages/Taxonstand/versions/2.1/topics/TPL)). To generate suggested name change for a specific study, run: 

```{r, eval=FALSE, echo=TRUE}
source("R/setup.R")
check_study_taxa("Blackman_2014")
```

TaxonStand has been configured in the above function to only permit relatively certain changes (e.g. with a minor change to spelling or known synonym). 

If TaxonStand fails to find a suitable alignment, and you have identified one yourself, you can add it to the metadata by running

```{r, eval=FALSE, echo=TRUE}
add_taxnomic_change(study, find, replace, reason)
```

# Contributing

There 

1. Reporting Errors
2. Refining documentation
3. Value adding / expanding existing data
4. Contributing new data


## Reporting errors

If you notice a possible error in Austraits, please [post an issue here](https://github.com/traitecoevo/austraits/issues), describing the error and possible fix in detail. If you can, please provide code illustrating the problem.

## Refining documentation

##  Value adding / expanding existing data

If you would like to value-add to Austraits in some other way, please get in contact by [posting an issue](https://github.com/traitecoevo/austraits/issues) with an idea or offer of time.


## Contributing new data

We gladly accept new data contributions to Austraits. In the future we hope to publish a data paper, including contributors as co-authors on the article.

If you would like to contribute data, the requirements are:

1. Data were collected for Australian plant species growing in Australia
2. You collected data on one of the traits list in the [trait definitions table](config/definitions_traits.csv).
3. You are willing to release the data under an open license for reuse by the scientific community.
4. That you make it is as easy as possible for us to incorporate your data by carefully following the instructions below.

By far our preferred way of contributing is for you to fork the database in github, add your dataset then send us a [pull request](https://help.github.com/articles/using-pull-requests/). If this is not possible, you could email the relevant files (see above) to Rachael Gallagher.

To contribute, please follow the steps below. It is important that all steps are followed so that our automated workflow proceeds without problems.

1. Create a new folder with name corresponding to the paper or study of the dataset, e.g. `Gallagher_2014` (do not include *et al* or similar).
2. Prepare the following files:
	* `data.csv`: a table of data in comma-separated values format, with data for each individual plant on a single row
	* `metadata.yml`: description of the metadata.

It may help to download one of the [existing datasets](https://github.com/traitecoevo/austraits/tree/master/data) and use it as a template for your own files and a guide on required content. You should look at the files in the [config folder](https://github.com/traitecoevo/austraits/tree/master/config), in particular the `definitions` files for the list of traits we cover.


The elements `traits` and `substitutions` are designed to covert into tables. You can see how they look as tables with code like the following:

```{r, echo=TRUE, results="show"}
source("R/support.R")

metadata <- read_yaml("data/Blackman_2014/metadata.yml")

my_df <- list_to_df(metadata[["traits"]])
my_df
```

Similarly we can convert a table to yaml as follows:

```{r, echo=TRUE, results="show"}
my_list <- df_to_list(my_df)
write_yaml(my_list, "tmp.yml")
```

```{r}
# Delete file we just created
unlink("tmp.yml")
```


### Adding data to Austraits

Once you have prepared your data files, add the relevant folder into the `data` directory. You can then rebuild the dataset, including your dataset.

To do so you will need to rerun the `bootstrap.R` script, which will update the `remake.yml`files with appropriate rules for the new dataset (similarly if you remove datasets, do the same). (At this stage, [remake](https://github.com/richfitz/remake) offers no looping constructs (on purpose) so for now at least we generate the remake file using [whisker](https://github.com/edwindj/whisker).)

See doc on adding Custom R code

### Tests

You can also run some automated tests to ensure the dataset meets required setup. The tests run through a collection of pre-specified checks on the files for each study. The output alerts you to possible issues needing to be fixed, by comparing the data in the files with expected structure and allowed values, as specified in the definitions. 

To run the tests, the variable `dataset_ids` must be defined in the global namespace, containing a vector of ids to check. For example

```{r, eval=FALSE, echo=TRUE}
# load relevant functions
source("R/setup.R")

# Tests run test on one study
dataset_ids <- "Bragg_2002"
run_tests()

# Tests run test on all studies
dataset_ids <- dir("data")
run_tests()
```

### Reports  / quality checks


Reports are written in [Rmarkdown](https://rstudio.github.io/rmarkdown/) and generated via the [knitr](https://cran.r-project.org/web/packages/knitr/) package. Several types of report are available. Templates are stored in the folder `reports`. 

```{r, eval=FALSE, echo=TRUE}
austraits <- remake::make("austraits")
source("R/report_utils.R")
build_study_report("Wright_2002")
```

Guidelines for writing report code

- use knitr chunk options: https://rmarkdown.rstudio.com/lesson-3.html
- use tidyverse style and format: http://htmlpreview.github.io/?https://github.com/nicercode/2018_BEES_regression/blob/master/tidyverse.html
- use kableExtra for styling: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html

**Maps:** We use the package [leaflet](https://cran.r-project.org/web/packages/leaflet/index.html) to generate interactive maps via the JavaScript 'Leaflet' framework and based on the [Open street map](https://www.openstreetmap.org/).


# Usage examples

```{r setup_usage, echo=FALSE, message=FALSE, warning=FALSE, results="hide"}
# knitr defaults
knitr::opts_chunk$set(echo=TRUE, cache=FALSE, results='show', message=TRUE, warning=TRUE)
```


The following section provides examples for users of `R` on manipulating the AusTraits dataset. Users of other platforms can follow similar steps using commands specific to their platform. 

We like using functions from packages like [dplyr](https://dplyr.tidyverse.org/), [readr](https://readr.tidyverse.org/), [tidyr](https://tidyr.tidyverse.org/) and [`magrittr`](https://magrittr.tidyverse.org/) in the [tidyverse](https://www.tidyverse.org/) to manipulate data. These packages can be loaded individually, or together by running:

```{r, eval=FALSE}
# install.packages("tidyverse")
library(tidyverse)
```

The examples below assume you have the tidyverse installed and loaded. This is not essential, but without these packages the examples below won't work.

For anyone needing to learn about the tidyverse, you will in particualr want to read up on [dplyr](https://dplyr.tidyverse.org/) and [the pipe operator `%>%` from `magrittr`](https://magrittr.tidyverse.org/), which pipes output from one command into the next command.

In addtion, we have included some helper functions for common manipulations of the data. These are available in the file `austraits.R` (TODO: where will users access this). To make these unctions availble, source the file prior to use:

```{r}
source("R/austraits.R")
```


## Loading data

There are several ways to access the Austrats data, including 

- downloading plain text files and loading these into R manually
- using the `austraits` R package to fetch and laod particular versions of the data (not yet available)
- rebuilding the Austraits data from scratch (see instructions above)
- downlaoding the compressed `austraits.rds` binary and loading this directly into R.

These istructions are written assuming you have followed the latter approach. 

Let's assume you have a variable `path` with the directory of your data. You can then load the Austraits data package using the `readRDS` package  

```{r, eval=FALSE}
austraits <- file.path(path, "austraits.rds") %>% readRDS()
```

You should now have a object called `austraits` with the following elements: 
```{r}
names(austraits)
```

These names correpsond to the sections described in full above under ["elements of austraits"](#elements_of_austraits). 

The trait data are in the element called data

```{r}
austraits$data
```
(Note that data appears as a `tibble` rather than a `data.frame`. Tibbles are an enhanced type dataframe, with some desriable features, such as not printing the whole dataframe to screen. (If you prefer, you can easily use a traditional R `data.frame` by converting it using `df <- data.frame(austraits$data)`. But from here on we'll assume you're stikcing with a tibble.)

## Taking subsets / extracting a particular trait or study

Using the `dplyr`, it's easy to subset by rows using `filter`. this approach can be used to filter the data to particualr trait or study:

```{r}
austraits$data %>% 
  filter(trait_name == "leaf_area")
```

```{r}
austraits$data %>% 
  filter(dataset_id == "Blackman_2014")
```

We can select particualr columns from the whole or filtered dataset using `select`:

```{r}
austraits$data %>% 
  select(species_name, observation_id, trait_name, value)
```

The file `austraits.R` also include prebuilt functions for extracting a particular trait or study. The difference with the examples above, is that these functions also subset the other tables and elements of the data, not just the main data table. So we need to provide the entire `austraits` object and a `dataset_id`:

```{r B14}
data_B14 <- extract_dataset(austraits, "Blackman_2014")
```

As wiith the the main `austraits` object, this new dataset has multiple elements:
```{r}
names(data_B14)
```
but the length of the datasets is smaller:
```{r countrows}
count_rows <- function(obj) {c(nrow(obj$data), nrow(obj$context), nrow(obj$species_list))}
# main data
austraits %>% count_rows()
# subset
data_B14 %>% count_rows()
```

A similar function enables subsetting to a particualr trait, including the various other tables:

```{r}
data_LS <- extract_trait(austraits, "leaf_width")
```

As wiith the the main `austraits` object, this new dataset has multiple elements:
```{r}
names(data_LS)
```
but the length of the datasets is smaller:
```{r}
# main data
austraits %>% count_rows()
# subset
data_LS %>% count_rows()
```

## Merging with taxonomic data

Limited taxonomic infomration is provided in the main table `data`, only `original_name` (the original name provided by the authors) and `species_name` (the aligned taxonomix name; see [species taxonomy](#species_taxonomy) for details). But further infomration is available in the table `species_list`:

```{r}
austraits$species_list
```

You can merge this information in with the main dataset using the `species_name` as a an indentifier linking both tables:

```{r taxonomic, results='show'}
data2 <- austraits$data %>% 
          left_join(by="species_name", austraits$species_list)

names(data2)
```

Similarly we could merge in only family information by using `select` to reduce the second table before merging:

```{r taxonomic2, results='show'}
data2 <- austraits$data %>% 
          left_join(by="species_name", select(austraits$species_list, species_name, family))

names(data2)
```

## Merging with location data

As with taxonomic infomration, limited infomration about location is provided in the main table `data`.  But further infomration is available in the table `context`:

```{r}
austraits$context
```

As with the main table of trait data, this information is in long format. Depending on the study, a variety of contextual information may have been provided, including

```{r}
austraits$context$trait_name %>% table() %>% sort(decreasing=TRUE) %>% .[1:10]
```

In this example we'll just focus on location details. Before merging in with the main data table let's convert this data from long to wide format:

```{r}
sites <- austraits$context %>% 
  filter(trait_name %in%  c("longitude (deg)","latitude (deg)")) %>% 
  spread(trait_name, value)
sites
```

We can now merge in with the main data table using combinations of `dataset_id` and `site_name` as indetifiers from both tables:

```{r}
data_sites <- left_join(by=c("dataset_id", "site_name"), austraits$data, sites)

names(data_sites)
```

## Converting from long to wide format

As discussed above, the main data table in `austraits` is distributed in long format. A long format has each measurment on a different row, and just a single column for all the value. By contrast, a dataset in wide format has data for each different trait in it's own column. The reason we use long format is mainly for efficiency. We have data from `r austraits$data$trait_name %>% unique() %>% length()` different traits, so in wide format we'd need at least this many columns. With many species, the file size gets very large very quickly. Other benefits of long format are that we can include columns for `units`, `value_type`, and `replicates`, which we could not in wide format (without created 3 more columns for each traits). 

For many analyses, however, you'll want to use wide format. We hve therevor provided the ability to convert between the two formats. In wie fromat, each trait appears in it's own column and measurments from the same obseravtion (ideally indivdual, but in floras may be a species) appear on the same row.  

As the entire austraits dataset is quite large, we recomend frst subsetting the data before spreading from long to wide fromat. You may also need to reduce the number of measurements in any one obseravtion (see next section). For this first example we'll sue the dataset `Blackman_2014`. 

First extract the trait data from the `Blackman_2014` study:

```{r}
data <- austraits$data %>% 
  filter(dataset_id == "Blackman_2014")
data
```
Now use the inbuilt function `spread_trait_data` to convert from long to wide:

```{r}
data_spread <- spread_trait_data(data)
```
This function spreads not only the data in the column `value`, but also other columns. The retruned object is a list with a number of wide tables:

```{r}
names(data_spread)
```
Looking at each of these we see a table in wide format (i.e. with each trait being a column), as well as indietifying columns at the start:
```{r}
data_spread$value
```
The other tables have an indentical fromat

```{r}
data_spread$unit
```
...etc

The new dataset can then be used to plot traits against each other, e.g.
```{r, warning=FALSE}
data_spread$value %>%
  mutate(specific_leaf_area = as.numeric(specific_leaf_area), 
         photosynthetic_rate_per_area = as.numeric(photosynthetic_rate_per_area)) %>%
  ggplot(aes(x=specific_leaf_area, y = photosynthetic_rate_per_area, colour =site_name)) +
  geom_point()
```

There is also a function to convert back from wide to long format:

```{r}
data2 <- gather_trait_data(data_spread, austraits$definitions)
```

This manipulation should recover the orginal dataset.

Original:
```{r}
data2
```
After conversion
```{r}
data
```
Just to be sure we can run a check:
```{r}
all.equal(data, data2)
```

Note that the function `gather_trait_data` also needs the element `austraits$defintions` to run successuflly. 

### Datasets with mutiple measurments per observation

The above example works easily because there is only a single measurement of each trait per `observation_id`. But this is not always the case. Many datasets include multiple records per `observation_id`, for example studies reporting multiple `value_types` per `observation_id`. An example is the `AusGrass_2014` datasets:

```{r}
data <- austraits$data %>% 
  filter(dataset_id == "AusGrass_2014")
data
```
Note the dataset includes multiple value_types: `expert_min` and `expert_max`. If you try running `spread_trait_data` on this data it will fail: 

```{r, eval=FALSE}
data_spread <- spread_trait_data(data)
```
```
## Error: Duplicate identifiers for rows (2929, 2930), (2936, 2937), (3015, 3016), (2975, 2976), ....
```

So before converting from long to wide we use an additonal function called `bind_trait_values` to collapse all the different measurements for a given `trait_name` and `observation_id` into a single cell:

```{r}
data_bind <- bind_trait_values(data)
```
This function binds data from multiple rows together, seraprting with the string ``--`. This coccurs for columns `value`, `value_type`, and `replicates`. Looking at the table we can see the bound values:

```{r}
data_bind %>% 
  filter(grepl("--", value_type)) %>% 
  select(-dataset_id, -site_name, -original_name)
```

Using this new dataset we can now go from long to wide:

```{r}
data_spread <- spread_trait_data(data_bind)
```

The bound data values are carried over to the new dataset:
```{r}
data_spread$value
```

As previously, we can also convert back again:

```{r}
data_bind2 <- gather_trait_data(data_spread, austraits$definitions)
```

Thsi gets us back to the intermediate dataset
```{r}
all.equal(data_bind, data_bind2)
```

And then finally we can separate out the values that have been bound together:

```{r}
data2 <- separate_trait_values(data_bind2, austraits$definitions)
```

We should now have a dataset identical to our original. Just to be sure we can run a check:
```{r}
all.equal(data, data2)
```

Using pipes we can put all these steps together to short the full range of steps:
 
```{r}
data %>% 
 bind_trait_values() %>% 
 spread_trait_data() %>% 
 gather_trait_data() %>% 
 separate_trait_values(austraits$definitions) -> data2

all.equal(data, data2)
```

## Categorical vs numerical traits 

List of categorical traits:

```{r, echo=TRUE, results="show"}
traits_all <- austraits$data$trait_name %>% unique()  %>% sort()

traits_all[trait_is_categorical(traits_all, austraits$definitions)]
```

list of numerical traits:

```{r, echo=TRUE, results="show"}
traits_all[trait_is_numeric(traits_all, austraits$definitions)]
```

# Appendices

## Acknowledgements


## File types

### CSV 

### YAML files


yml: The `yml` file extension (pronounced "YAML") [is a type structured data file](https://en.wikipedia.org/wiki/YAML), that is both human and machine readable. The information in it appears under various labels, which are imported into Austraits. You can edit it any text editor, or also in Rstudio. Generally, yml is used in situations where a table does not suit because of variable lengths and or nested structures.
This document outlines how to describe metadata for any given study

The metadata is compiled in a `.yml` file, a structured data file where information is presented in a hierarchical format. It has the advantage over a spreadsheet in that the nested “headers” can have variable numbers of categories. The data under each of the hierarchical headings are easily extracted by R.

Assumed character unless specified otherwise

possible types:

- `character`: 
- `numeric`: must have fields `description`, `type`, `units`, `values` with filed `minimum` and `maximum`.
- `categorical`: Unlike character, only specific values are allowed. must have fields `description`, `type`,and `values`, with the latter including a list of possible values.
- `table`:
- `list`:
- `array`:

## Adding custom R code into metadata.yml

Occasionally all the changes we want to make to dataset may not fit into the prescribed workflow used in Austraits. For example, we assume each trait has a single unit. But there are a few datasets where data on different rows have different units. So we want to make to make some custom modifications to this particular dataset before the common pipeline of operations gets applied. To make this possible, the workflow allows for some custom R code to be run as a first step in the processing pipeline. That pipeline (in the function [`read_data_study`](https://github.com/traitecoevo/austraits/blob/master/R/steps.R#L59)) looks like:

```{r, eval=FALSE, echo=TRUE}
  # load and clean trait data
  data <- read_csv(filename_data_raw, col_types = cols()) %>%
    custom_manipulation(metadata[["config"]][["custom_R_code"]])() %>%
    parse_data(dataset_id, metadata) %>%
    add_all_columns(definitions, "data") %>%
    flag_unsupported_traits(definitions) %>%
    convert_units(definitions, unit_conversion_functions) %>%
    flag_unsupported_values(definitions) %>%
    update_taxonomy(metadata) %>%
    mutate(value=tolower(value))
```

Note the second line. 

### Example problem 

As an example, `Barlow_1981` has multiple units per traits. Check it out:

```{r}
library(readr)
library(yaml)
```

Load the data
```{r}
key <- "Barlow_1981"
data <- read_csv(file.path("data", key, "data.csv"), col_types = cols(.default = "c"))
metadata <- read_yaml(file.path("data", key, "metadata.yml"))
```

Here's the problem - note tat several traits have multiple units used:

```{r}
table(data$trait, data$units)
```

So you want to write some R code that fixes this and gets the dataset into the processing pipeline, satisfying all the assumptions.

### Developing solutions

We want to write some custom R code that will appear in the `metadata.yml` file for that study, under a title `config` -> `custom_R_code`. E.g. see this example for [data/Barlow_1981/metadata.yml](https://github.com/traitecoevo/austraits/blob/master/data/Barlow_1981/metadata.yml).

Your code should assume a single object called `data`. And apply whatever fixes are needed. Also it should be

- fully self contained (we're not going to use any of the other remake machinery here)
- have semi colons `;` at the end of each line. This will be needed because we're adding the code to the `metadata.yml` file and newlines get lost when reading in the file.

The workflow is to first develop some code that applies a suitable fix. E.g. for Barlow_1981 here is the code we eventually applied to the object `data` loaded above:

```{r, eval=FALSE}
metadata[["config"]][["custom_R_code"]] %>% gsub(";", ";\n", .) %>% writeLines()
```

Running this removes the problem with multiple units:
```{r, echo=TRUE, results="show"}
table(data$trait, data$units)
```
(we can ignore the NULLs here, these are when data and units are both NA. Those get pruged furtehr down the pipeline).

Once you have some working code, you then want to add it into your yml file under a group `config` -> `custom_R_code`. 

And then check it works.

Let's assume you added it in, so we'll load the metadata (and also reload the data)

In the build process we use the function `custom_manipulation` to create a function that accepts a data frame and modifies it according to the code in `txt`

```{r, echo=TRUE, comment=""}
custom_manipulation
```

So now lets use it to create a function
```{r, echo=TRUE, results="show"}
f <- custom_manipulation(metadata[["config"]][["custom_R_code"]])
f
```

And finally we can apply the function to our data:
```{r, echo=TRUE, results="show"}
data2 <- f(data)
```
(If it fails at this point it won't work in the build). 

Now let's compare it to our original data (the columns units and values should now differ)

```{r, echo=TRUE, results="show"}
all.equal(data, data2)
```

And also see the units and traits:

```{r, results="show"}
table(data2$trait, data2$units)
```

Finally, check it works in the context of loading the metadata:

```{r, results="show"}
data2 <- custom_manipulation(metadata[["config"]][["custom_R_code"]])(data)
all.equal(data, data2)
```

Now you're ready to go. 

